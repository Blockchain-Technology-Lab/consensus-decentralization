{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Blockchain Pooling Analysis - Documentation This is the documentation for the Blockchain Pooling Analysis tool developed by the University of Edinburgh's Blockchain Technology Lab. The tool is responsible for analyzing pooling behavior of various blockchains and measuring their subsequent decentralization levels. The relevant source code is available on GitHub . Overview The tool consists of the following modules: Parser Mapping Metrics The parser is responsible for pre-processing the raw data that comes from a full node. It produces a file with all the information that is needed for the mapping. The mapping takes the output of the parser and combines it with some other sources of information. It then outputs a file that reveals the distribution of resources to different entities. In this context, \"resources\" correspond to the number of produced blocks. This distribution is the input for the metrics module, which tracks various decentralization-related metrics and produces files with the results. More details about the different modules can be found in the corresponding Parser , Mapping and Metrics pages. Currently, the supported ledgers are: Bitcoin Bitcoin Cash Cardano Dash Dogecoin Ethereum Litecoin Tezos Zcash We intend to add more ledgers to this list in the future. Contributing This is an open source project licensed under the terms and conditions of the MIT license and CC BY-SA 4.0 . Everyone is welcome to contribute to it by proposing or implementing their ideas. Example contributions include, but are not limited to, reporting potential bugs, supplying useful information for the mappings of supported ledgers, adding support for a new ledger, or making the code more efficient. All contributions to the project will also be covered by the above-mentioned license. When making changes in the code, contributors are required to fork the project's repository first and then issue a pull request with their changes. Each PR will be reviewed before being merged to the main branch. Bugs can be reported in the Issues page. Other comments and ideas can be brought up in the project's Disccussions .","title":"Home"},{"location":"#blockchain-pooling-analysis-documentation","text":"This is the documentation for the Blockchain Pooling Analysis tool developed by the University of Edinburgh's Blockchain Technology Lab. The tool is responsible for analyzing pooling behavior of various blockchains and measuring their subsequent decentralization levels. The relevant source code is available on GitHub .","title":"Blockchain Pooling Analysis - Documentation"},{"location":"#overview","text":"The tool consists of the following modules: Parser Mapping Metrics The parser is responsible for pre-processing the raw data that comes from a full node. It produces a file with all the information that is needed for the mapping. The mapping takes the output of the parser and combines it with some other sources of information. It then outputs a file that reveals the distribution of resources to different entities. In this context, \"resources\" correspond to the number of produced blocks. This distribution is the input for the metrics module, which tracks various decentralization-related metrics and produces files with the results. More details about the different modules can be found in the corresponding Parser , Mapping and Metrics pages. Currently, the supported ledgers are: Bitcoin Bitcoin Cash Cardano Dash Dogecoin Ethereum Litecoin Tezos Zcash We intend to add more ledgers to this list in the future.","title":"Overview"},{"location":"#contributing","text":"This is an open source project licensed under the terms and conditions of the MIT license and CC BY-SA 4.0 . Everyone is welcome to contribute to it by proposing or implementing their ideas. Example contributions include, but are not limited to, reporting potential bugs, supplying useful information for the mappings of supported ledgers, adding support for a new ledger, or making the code more efficient. All contributions to the project will also be covered by the above-mentioned license. When making changes in the code, contributors are required to fork the project's repository first and then issue a pull request with their changes. Each PR will be reviewed before being merged to the main branch. Bugs can be reported in the Issues page. Other comments and ideas can be brought up in the project's Disccussions .","title":"Contributing"},{"location":"data/","text":"Data collection Currently, the data for the analysis of the different ledgers is collected through Google BigQuery . Note that when saving results from BigQuery you should select the option \"JSONL (newline delimited)\". Sample data Bitcoin Sample raw Bitcoin data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_bitcoin.transactions`.outputs FROM `bigquery-public-data.crypto_bitcoin.transactions` JOIN `bigquery-public-data.crypto_bitcoin.blocks` ON `bigquery-public-data.crypto_bitcoin.transactions`.block_number = `bigquery-public-data.crypto_bitcoin.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2017-12-31' Bitcoin Cash Sample raw Bitcoin Cash data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_bitcoin_cash.transactions`.outputs FROM `bigquery-public-data.crypto_bitcoin_cash.transactions` JOIN `bigquery-public-data.crypto_bitcoin_cash.blocks` ON `bigquery-public-data.crypto_bitcoin_cash.transactions`.block_number = `bigquery-public-data.crypto_bitcoin_cash.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31' Cardano Sample raw Cardano data are available here . They can be retrieved using Google BigQuery with the following query: SELECT `iog-data-analytics.cardano_mainnet.block`.slot_no as number, `iog-data-analytics.cardano_mainnet.pool_offline_data`.ticker_name as coinbase_param, `iog-data-analytics.cardano_mainnet.block`.block_time as timestamp, `iog-data-analytics.cardano_mainnet.block`.pool_hash FROM `iog-data-analytics.cardano_mainnet.block` LEFT JOIN `iog-data-analytics.cardano_mainnet.pool_offline_data` ON `iog-data-analytics.cardano_mainnet.block`.pool_hash = `iog-data-analytics.cardano_mainnet.pool_offline_data`.pool_hash WHERE `iog-data-analytics.cardano_mainnet.block`.block_time > '2020-12-31' Dash Sample raw Dash data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_dash.transactions`.outputs FROM `bigquery-public-data.crypto_dash.transactions` JOIN `bigquery-public-data.crypto_dash.blocks` ON `bigquery-public-data.crypto_dash.transactions`.block_number = `bigquery-public-data.crypto_dash.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31' Dogecoin Sample raw Dogecoin data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_dogecoin.transactions`.outputs FROM `bigquery-public-data.crypto_dogecoin.transactions` JOIN `bigquery-public-data.crypto_dogecoin.blocks` ON `bigquery-public-data.crypto_dogecoin.transactions`.block_number = `bigquery-public-data.crypto_dogecoin.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2019-12-31' Ethereum Sample raw Ethereum data are available here . They can be retrieved using Google BigQuery with the following query: SELECT number, timestamp, miner as coinbase_addresses, extra_data as coinbase_param FROM `bigquery-public-data.crypto_ethereum.blocks` WHERE timestamp > '2018-12-31' Litecoin Sample raw Litecoin data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_litecoin.transactions`.outputs FROM `bigquery-public-data.crypto_litecoin.transactions` JOIN `bigquery-public-data.crypto_litecoin.blocks` ON `bigquery-public-data.crypto_litecoin.transactions`.block_number = `bigquery-public-data.crypto_litecoin.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31' Tezos Sample raw Tezos data are available here . They can be retrieved using Google BigQuery with the following query: SELECT level as number, timestamp, baker as coinbase_addresses FROM `public-data-finance.crypto_tezos.blocks` WHERE timestamp > '2020-12-31' Zcash Sample raw Zcash data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_zcash.transactions`.outputs FROM `bigquery-public-data.crypto_zcash.transactions` JOIN `bigquery-public-data.crypto_zcash.blocks` ON `bigquery-public-data.crypto_zcash.transactions`.block_number = `bigquery-public-data.crypto_zcash.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31'","title":"Data Collection"},{"location":"data/#data-collection","text":"Currently, the data for the analysis of the different ledgers is collected through Google BigQuery . Note that when saving results from BigQuery you should select the option \"JSONL (newline delimited)\".","title":"Data collection"},{"location":"data/#sample-data","text":"","title":"Sample data"},{"location":"data/#bitcoin","text":"Sample raw Bitcoin data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_bitcoin.transactions`.outputs FROM `bigquery-public-data.crypto_bitcoin.transactions` JOIN `bigquery-public-data.crypto_bitcoin.blocks` ON `bigquery-public-data.crypto_bitcoin.transactions`.block_number = `bigquery-public-data.crypto_bitcoin.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2017-12-31'","title":"Bitcoin"},{"location":"data/#bitcoin-cash","text":"Sample raw Bitcoin Cash data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_bitcoin_cash.transactions`.outputs FROM `bigquery-public-data.crypto_bitcoin_cash.transactions` JOIN `bigquery-public-data.crypto_bitcoin_cash.blocks` ON `bigquery-public-data.crypto_bitcoin_cash.transactions`.block_number = `bigquery-public-data.crypto_bitcoin_cash.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31'","title":"Bitcoin Cash"},{"location":"data/#cardano","text":"Sample raw Cardano data are available here . They can be retrieved using Google BigQuery with the following query: SELECT `iog-data-analytics.cardano_mainnet.block`.slot_no as number, `iog-data-analytics.cardano_mainnet.pool_offline_data`.ticker_name as coinbase_param, `iog-data-analytics.cardano_mainnet.block`.block_time as timestamp, `iog-data-analytics.cardano_mainnet.block`.pool_hash FROM `iog-data-analytics.cardano_mainnet.block` LEFT JOIN `iog-data-analytics.cardano_mainnet.pool_offline_data` ON `iog-data-analytics.cardano_mainnet.block`.pool_hash = `iog-data-analytics.cardano_mainnet.pool_offline_data`.pool_hash WHERE `iog-data-analytics.cardano_mainnet.block`.block_time > '2020-12-31'","title":"Cardano"},{"location":"data/#dash","text":"Sample raw Dash data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_dash.transactions`.outputs FROM `bigquery-public-data.crypto_dash.transactions` JOIN `bigquery-public-data.crypto_dash.blocks` ON `bigquery-public-data.crypto_dash.transactions`.block_number = `bigquery-public-data.crypto_dash.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31'","title":"Dash"},{"location":"data/#dogecoin","text":"Sample raw Dogecoin data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_dogecoin.transactions`.outputs FROM `bigquery-public-data.crypto_dogecoin.transactions` JOIN `bigquery-public-data.crypto_dogecoin.blocks` ON `bigquery-public-data.crypto_dogecoin.transactions`.block_number = `bigquery-public-data.crypto_dogecoin.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2019-12-31'","title":"Dogecoin"},{"location":"data/#ethereum","text":"Sample raw Ethereum data are available here . They can be retrieved using Google BigQuery with the following query: SELECT number, timestamp, miner as coinbase_addresses, extra_data as coinbase_param FROM `bigquery-public-data.crypto_ethereum.blocks` WHERE timestamp > '2018-12-31'","title":"Ethereum"},{"location":"data/#litecoin","text":"Sample raw Litecoin data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_litecoin.transactions`.outputs FROM `bigquery-public-data.crypto_litecoin.transactions` JOIN `bigquery-public-data.crypto_litecoin.blocks` ON `bigquery-public-data.crypto_litecoin.transactions`.block_number = `bigquery-public-data.crypto_litecoin.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31'","title":"Litecoin"},{"location":"data/#tezos","text":"Sample raw Tezos data are available here . They can be retrieved using Google BigQuery with the following query: SELECT level as number, timestamp, baker as coinbase_addresses FROM `public-data-finance.crypto_tezos.blocks` WHERE timestamp > '2020-12-31'","title":"Tezos"},{"location":"data/#zcash","text":"Sample raw Zcash data are available here . They can be retrieved using Google BigQuery with the following query: SELECT block_number as number, block_timestamp as timestamp, coinbase_param, `bigquery-public-data.crypto_zcash.transactions`.outputs FROM `bigquery-public-data.crypto_zcash.transactions` JOIN `bigquery-public-data.crypto_zcash.blocks` ON `bigquery-public-data.crypto_zcash.transactions`.block_number = `bigquery-public-data.crypto_zcash.blocks`.number WHERE is_coinbase is TRUE AND timestamp > '2018-12-31'","title":"Zcash"},{"location":"mappings/","text":"Mappings A mapping obtains the parsed data (from output/<project_name>/parsed_data.json ) and outputs a csv file that maps blocks to entities, structured as follows: Entity,Resources <name of entity>,<(int) number of blocks> The name of the csv file is the timeframe, over which the mapping was executed (e.g., 2021-04.csv ). The file is stored in the project's output directory ( output/<project_name>/ ). The logic of the mapping depends on the type of clustering we want to achieve. So, different mappings will output different results, even if applied on the same data. An exception to this is the \"no-cluster\" mapping, which maps blocks to coinbase addresses, so it doesn't perform any extra processing on the raw data. Pool Information To assist the mapping process, the directory helpers/pool_information/ contains files named <project_name>.json , with relevant pool information, structured as follows: { \"clusters\": { \"<cluster name>\": [ {\"name\": \"<pool name>\", \"from\": \"<from>\", \"to\": \"<to>\", \"source\": \"<source of information>\"} ] }, \"coinbase_tags\": { \"<pool tag>\": { \"name\": \"<pool name>\", \"link\": \"<pool website>\" } }, \"pool_addresses\": { \"<address>\": {\"name\": \"<pool name>\", \"from\": \"<from>\", \"to\": \"<to>\", \"source\": \"<source of information>\"}, } } In this file: clusters refers to pools that share infrastructure: for each pool in a cluster, the following values should be defined: <from> sets the beginning of the control of the pool by the cluster; the first day of the timeframe is chosen; for example, if 2022 , then the beginning is set to 2022-01-01 ); if <from> is empty, then the control existed since the pool's inception. <to> sets the end of the control of the pool by the cluster; the end is exclusive, i.e., it defines the beginning of the control transition; for example, if 2022 , the end of the control is 31-12-2021 if <to> is empty, then the control is still active. <source of information> should be either (i) comma-separated keywords or (ii) a url with the clustering information; this information should be publicly-available and reproducible (for example, a link to a community or company, with information that cannot be verified independently, is not acceptable); keywords: for Cardano, homepage can be used for pools that define the same homepage in their metadata json file (published on0chain) <pool tag> is the tag that a pool inserts in a block's coinbase parameter, in order to claim a block as being mined by the pool; in projects that do not rely on the coinbase parameter (e.g., Cardano, Tezos) the tag is just the name of the pool (Tezos) or its ticker (Cardano). pool_addresses define control of an address by a pool; the structure is the same as clusters . Pool Ownership The file helpers/legal_links.json defines legal links between pools and companies, based on off-chain information. For example, it defines ownership information of a pool by a company. The structure of the file is as follows: { \"<parent company>\": [ {\"name\": \"<pool name>\", \"from\": \"<start date>\", \"to\": \"<end date>\", \"source\": \"<source of information>\"} ] } The values for each entry are the same as clusters in the above pool information.","title":"Mappings"},{"location":"mappings/#mappings","text":"A mapping obtains the parsed data (from output/<project_name>/parsed_data.json ) and outputs a csv file that maps blocks to entities, structured as follows: Entity,Resources <name of entity>,<(int) number of blocks> The name of the csv file is the timeframe, over which the mapping was executed (e.g., 2021-04.csv ). The file is stored in the project's output directory ( output/<project_name>/ ). The logic of the mapping depends on the type of clustering we want to achieve. So, different mappings will output different results, even if applied on the same data. An exception to this is the \"no-cluster\" mapping, which maps blocks to coinbase addresses, so it doesn't perform any extra processing on the raw data.","title":"Mappings"},{"location":"mappings/#pool-information","text":"To assist the mapping process, the directory helpers/pool_information/ contains files named <project_name>.json , with relevant pool information, structured as follows: { \"clusters\": { \"<cluster name>\": [ {\"name\": \"<pool name>\", \"from\": \"<from>\", \"to\": \"<to>\", \"source\": \"<source of information>\"} ] }, \"coinbase_tags\": { \"<pool tag>\": { \"name\": \"<pool name>\", \"link\": \"<pool website>\" } }, \"pool_addresses\": { \"<address>\": {\"name\": \"<pool name>\", \"from\": \"<from>\", \"to\": \"<to>\", \"source\": \"<source of information>\"}, } } In this file: clusters refers to pools that share infrastructure: for each pool in a cluster, the following values should be defined: <from> sets the beginning of the control of the pool by the cluster; the first day of the timeframe is chosen; for example, if 2022 , then the beginning is set to 2022-01-01 ); if <from> is empty, then the control existed since the pool's inception. <to> sets the end of the control of the pool by the cluster; the end is exclusive, i.e., it defines the beginning of the control transition; for example, if 2022 , the end of the control is 31-12-2021 if <to> is empty, then the control is still active. <source of information> should be either (i) comma-separated keywords or (ii) a url with the clustering information; this information should be publicly-available and reproducible (for example, a link to a community or company, with information that cannot be verified independently, is not acceptable); keywords: for Cardano, homepage can be used for pools that define the same homepage in their metadata json file (published on0chain) <pool tag> is the tag that a pool inserts in a block's coinbase parameter, in order to claim a block as being mined by the pool; in projects that do not rely on the coinbase parameter (e.g., Cardano, Tezos) the tag is just the name of the pool (Tezos) or its ticker (Cardano). pool_addresses define control of an address by a pool; the structure is the same as clusters .","title":"Pool Information"},{"location":"mappings/#pool-ownership","text":"The file helpers/legal_links.json defines legal links between pools and companies, based on off-chain information. For example, it defines ownership information of a pool by a company. The structure of the file is as follows: { \"<parent company>\": [ {\"name\": \"<pool name>\", \"from\": \"<start date>\", \"to\": \"<end date>\", \"source\": \"<source of information>\"} ] } The values for each entry are the same as clusters in the above pool information.","title":"Pool Ownership"},{"location":"metrics/","text":"Metrics A metric gets the mapped data (see above Mapping ) and outputs a relevant value. The implemented metrics are the following (with more to be added in the future): Nakamoto coefficient : The Nakamoto coefficient is the minimum number of entities that collectively produce more than 50% of the produced blocks within a given timeframe. The output of the metric is a tuple of the Nakamoto coefficient and the power percentage that these entities control. Gini coefficient : The Gini coefficient represents the degree of inequality in block production. The output of the metric a decimal number in [0,1]. Values close to 0 indicate equality (all entities in the system produce the same number of blocks) and values close to 1 indicate inequality (one entity produces most or all blocks). Entropy : Entropy represents the expected amount of information in the distribution of blocks across entities. Entropy is parameterized by a base rate \u03b1, which defines different types of entropy: (a) -1: min; (b) 0: Hartley; (c) 1: Shannon; (d) 2: collision. The output of the metric is a real number. Typically, a high number of different involved entities, each with approximately equal power, should yield high entropy. Each metric is implemented in a separate Python script in the folder metrics . Each script defines a function named compute_<metric_name> , which takes as input a dictionary of the form {'<entity name>': <number of resources>} (and possibly other relevant arguments) and outputs the corresponding metric values.","title":"Metrics"},{"location":"metrics/#metrics","text":"A metric gets the mapped data (see above Mapping ) and outputs a relevant value. The implemented metrics are the following (with more to be added in the future): Nakamoto coefficient : The Nakamoto coefficient is the minimum number of entities that collectively produce more than 50% of the produced blocks within a given timeframe. The output of the metric is a tuple of the Nakamoto coefficient and the power percentage that these entities control. Gini coefficient : The Gini coefficient represents the degree of inequality in block production. The output of the metric a decimal number in [0,1]. Values close to 0 indicate equality (all entities in the system produce the same number of blocks) and values close to 1 indicate inequality (one entity produces most or all blocks). Entropy : Entropy represents the expected amount of information in the distribution of blocks across entities. Entropy is parameterized by a base rate \u03b1, which defines different types of entropy: (a) -1: min; (b) 0: Hartley; (c) 1: Shannon; (d) 2: collision. The output of the metric is a real number. Typically, a high number of different involved entities, each with approximately equal power, should yield high entropy. Each metric is implemented in a separate Python script in the folder metrics . Each script defines a function named compute_<metric_name> , which takes as input a dictionary of the form {'<entity name>': <number of resources>} (and possibly other relevant arguments) and outputs the corresponding metric values.","title":"Metrics"},{"location":"output/","text":"Output","title":"Output"},{"location":"output/#output","text":"","title":"Output"},{"location":"parsers/","text":"Parsers The parser obtains raw data from a full node (see Data Collection page on how to obtain the required data). It parses the data and outputs a json file with a list of entries, each entry corresponding to a block. The input file should be placed in the input directory and named as <project_name>_raw_data.json . The output file is stored under output/<project_name>/parsed_data.json and is structured as follows: [ { \"number\": \"<block's number>\", \"timestamp\": \"<block's timestamp of the form: yyyy-mm-dd hh:mm:ss UTC>\", \"coinbase_addresses\": \"<address1>,<address2>\" \"coinbase_param\": \"<coinbase parameter>\" } ] number and timestamp are consistent among different blockchains. coinbase_addresses and coinbase_param vary, depending on each ledger. Specifically, coinbase_addresses corresponds to: Bitcoin , Bitcoin Cash , Dogecoin , Litecoin , Zcash , Dash : a string of comma-separated addresses which appear in the block's coinbase transaction with non-negative value (i.e., which are given part of the block's fees) Ethereum : the block's miner field Cardano : the hash of the pool that created the data, if defined, otherwise the empty string Tezos : the block's baker field The field coinbase_param corresponds to: Bitcoin , Bitcoin Cash , Dogecoin , Litecoin , Zcash , Dash : the field coinbase_param of the block's coinbase transaction Ethereum : the block's extra_data field Cardano : the ticker name of the pool that created the block, if defined, otherwise an empty string Tezos : there is no such field If using BigQuery, the queries for Bitcoin, Bitcoin Cash, Dogecoin, Litecoin, Zcash, Dash (see Data Collection ) return data that are parsed with the default_parser script in parsers . The query for Cardano returns data that is parsed using the cardano_parser script in parsers . All other queries return data already in the necessary parsed form, so they are parsed using a \"dummy\" parser.","title":"Parsers"},{"location":"parsers/#parsers","text":"The parser obtains raw data from a full node (see Data Collection page on how to obtain the required data). It parses the data and outputs a json file with a list of entries, each entry corresponding to a block. The input file should be placed in the input directory and named as <project_name>_raw_data.json . The output file is stored under output/<project_name>/parsed_data.json and is structured as follows: [ { \"number\": \"<block's number>\", \"timestamp\": \"<block's timestamp of the form: yyyy-mm-dd hh:mm:ss UTC>\", \"coinbase_addresses\": \"<address1>,<address2>\" \"coinbase_param\": \"<coinbase parameter>\" } ] number and timestamp are consistent among different blockchains. coinbase_addresses and coinbase_param vary, depending on each ledger. Specifically, coinbase_addresses corresponds to: Bitcoin , Bitcoin Cash , Dogecoin , Litecoin , Zcash , Dash : a string of comma-separated addresses which appear in the block's coinbase transaction with non-negative value (i.e., which are given part of the block's fees) Ethereum : the block's miner field Cardano : the hash of the pool that created the data, if defined, otherwise the empty string Tezos : the block's baker field The field coinbase_param corresponds to: Bitcoin , Bitcoin Cash , Dogecoin , Litecoin , Zcash , Dash : the field coinbase_param of the block's coinbase transaction Ethereum : the block's extra_data field Cardano : the ticker name of the pool that created the block, if defined, otherwise an empty string Tezos : there is no such field If using BigQuery, the queries for Bitcoin, Bitcoin Cash, Dogecoin, Litecoin, Zcash, Dash (see Data Collection ) return data that are parsed with the default_parser script in parsers . The query for Cardano returns data that is parsed using the cardano_parser script in parsers . All other queries return data already in the necessary parsed form, so they are parsed using a \"dummy\" parser.","title":"Parsers"},{"location":"setup/","text":"Setup Installation To install the pooling analysis tool, simply clone this GitHub repository: git clone https://github.com/Blockchain-Technology-Lab/pooling-analysis.git The tool is written in Python 3, therefore a Python 3 interpreter is required in order to run it locally. The requirements file lists the dependencies of the project. Make sure you have all of them installed before running the scripts. To install all of them in one go, run the following command from the root directory of the project: python -m pip install -r requirements.txt Execution The pooling analysis tool is a CLI tool. The run.py script in the root directory of the project invokes the required parsers, mappings and metrics, but it is also possible to execute each module individually. The following process describes the most typical workflow. Place all raw data (which could be collected from BigQuery for example; see Data Collection for more details) in the input directory, each file named as <project_name>_raw_data.json (e.g., bitcoin_raw_data.json ). By default, there is a (very small) sample input file for some supported projects; to use it, remove the prefix sample_ . Run python run.py --ledgers <ledger_1> <ledger_n> --timeframe <timeframe> to analyze the n specified ledgers for the given timeframe. Both arguments are optional, so it's possible to omit one or both of them; in this case, the default values will be used. Specifically: ledgers accepts any number of the supported ledgers (case-insensitive). For example, --ledgers bitcoin would run the analysis for Bitcoin, while --ledgers Bitcoin Ethereum Cardano would run the analysis for Bitcoin, Ethereum and Cardano. If the ledgers argument is omitted, then all supported ledgers are analyzed. The timeframe argument should be of the form YYYY-MM-DD (month and day can be omitted). For example, --timeframe 2022 would run the analysis for the year 2022, while --timeframe 2022-02 would do it for the month of February 2022. If the timeframe argument is omitted, then a monthly analysis is performed for each month between January 2018 and the current month. The script will print the output of each implemented metric for the specified ledgers and timeframe. All output files can then be found under the output directory, which is automatically created the first time the tool is run.","title":"How to use"},{"location":"setup/#setup","text":"","title":"Setup"},{"location":"setup/#installation","text":"To install the pooling analysis tool, simply clone this GitHub repository: git clone https://github.com/Blockchain-Technology-Lab/pooling-analysis.git The tool is written in Python 3, therefore a Python 3 interpreter is required in order to run it locally. The requirements file lists the dependencies of the project. Make sure you have all of them installed before running the scripts. To install all of them in one go, run the following command from the root directory of the project: python -m pip install -r requirements.txt","title":"Installation"},{"location":"setup/#execution","text":"The pooling analysis tool is a CLI tool. The run.py script in the root directory of the project invokes the required parsers, mappings and metrics, but it is also possible to execute each module individually. The following process describes the most typical workflow. Place all raw data (which could be collected from BigQuery for example; see Data Collection for more details) in the input directory, each file named as <project_name>_raw_data.json (e.g., bitcoin_raw_data.json ). By default, there is a (very small) sample input file for some supported projects; to use it, remove the prefix sample_ . Run python run.py --ledgers <ledger_1> <ledger_n> --timeframe <timeframe> to analyze the n specified ledgers for the given timeframe. Both arguments are optional, so it's possible to omit one or both of them; in this case, the default values will be used. Specifically: ledgers accepts any number of the supported ledgers (case-insensitive). For example, --ledgers bitcoin would run the analysis for Bitcoin, while --ledgers Bitcoin Ethereum Cardano would run the analysis for Bitcoin, Ethereum and Cardano. If the ledgers argument is omitted, then all supported ledgers are analyzed. The timeframe argument should be of the form YYYY-MM-DD (month and day can be omitted). For example, --timeframe 2022 would run the analysis for the year 2022, while --timeframe 2022-02 would do it for the month of February 2022. If the timeframe argument is omitted, then a monthly analysis is performed for each month between January 2018 and the current month. The script will print the output of each implemented metric for the specified ledgers and timeframe. All output files can then be found under the output directory, which is automatically created the first time the tool is run.","title":"Execution"}]}